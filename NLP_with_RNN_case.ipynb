{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1aJ3pMPypWIEqMhIu1z62XnAQN4YixJBh",
      "authorship_tag": "ABX9TyOl3JYHX3eDsjI7cBvrGltR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/modele-NLP/blob/main/NLP_with_RNN_case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fo4m7w-a6vy_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MziCt0sw68Gq",
        "outputId": "b3dc8e42-3640-4135-d45d-8d72eacddb26"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.14.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = '/content/drive/MyDrive/dane/shakespeare.txt'"
      ],
      "metadata": {
        "id": "-U91-5O87Xmm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'r').read()"
      ],
      "metadata": {
        "id": "Ai8g_s0-7eVj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D6pFp-U7iYp",
        "outputId": "17c82d70-23dc-4691-d67b-ae9efa66d282"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(vocab)\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpJqOJi-7qR4",
        "outputId": "7753c853-e4bc-4e93-b60c-bb23fe888d5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Vectorization\n",
        "\n",
        "The neural network can't take in the raw string data.\n",
        "We need to assign numbers to each character.\n",
        "\n",
        "Let's create two dictionaries that can go from numeric index to character and character to numeric index."
      ],
      "metadata": {
        "id": "JR2DWjHA77lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ind = {u:i for i, u in enumerate(vocab)}\n",
        "char_to_ind"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-XTiIZf8HQT",
        "outputId": "12a89a7a-ffe5-4817-f555-488f90770b9d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_to_char = np.array(vocab)\n",
        "ind_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuAxwsOl8S-y",
        "outputId": "d53f9661-77a7-4cbf-b42e-7b16c3ed6767"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])\n",
        "encoded_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5ldSHkB8c4J",
        "outputId": "899f8587-5590-4900-eb49-ccd500d9c51f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM8YW-qW9KIX",
        "outputId": "9ec926a7-1000-42c2-9d37-92c94380e77a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5445609,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = text[:100]\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YLTqhZGl-Ghf",
        "outputId": "b2c8f6a6-2044-4874-badc-3f2acd95344a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose mi\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNZyF92h-QVv",
        "outputId": "8a649333-07e4-4a5f-af72-448f489d17fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ogólnie rzecz biorąc, staramy się, aby model przewidywał następną znak o najwyższym prawdopodobieństwie, biorąc pod uwagę historyczną sekwencję znaków. Do nas (użytkownika) należy wybór długości tej historycznej sekwencji. Zbyt krótka sekwencja i nie mamy wystarczających informacji (np. biorąc pod uwagę literę \"a\", jaki jest następny znak), zbyt długa sekwencja i szkolenie zajmie zbyt dużo czasu i najprawdopodobniej nadmiernie dopasuje się do sekwencji znaków, które są nieistotne dla znaków dalej. Chociaż nie ma prawidłowego wyboru długości sekwencji, należy wziąć pod uwagę sam tekst, jak długie są w nim normalne frazy i rozsądne wyobrażenie o tym, które znaki / słowa są ze sobą powiązane."
      ],
      "metadata": {
        "id": "OJyUYVe3BS0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "607WtBpjBhr7",
        "outputId": "ba97dec5-efd5-4de4-c22a-9b60365cbc1b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line = \"From fairest creatures we desire increase\""
      ],
      "metadata": {
        "id": "riEgk6SmBmPk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h10pbkLiBox4",
        "outputId": "097f9f83-0a30-4e7c-ff40-376477b93396"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "part_stanza = \"\"\"From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\"\"\""
      ],
      "metadata": {
        "id": "9HQQ2KYHBzhn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(part_stanza)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD4VJtxRB32v",
        "outputId": "b26a3889-3647-4eed-9c23-1be9e6433177"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Sequences\n",
        "\n",
        "Rzeczywiste dane tekstowe będą sekwencją tekstową przesuniętą o jeden znak do przodu. Na przykład:\n",
        "\n",
        "Sequence In: \"Hello my name\"\n",
        "Sequence Out: \"ello my name\"\n",
        "\n",
        "\n",
        "Możemy użyć funkcji `tf.data.Dataset.from_tensor_slices`, aby przekonwertować wektor tekstowy na strumień indeksów znaków."
      ],
      "metadata": {
        "id": "gEO2ytUrB-Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 120"
      ],
      "metadata": {
        "id": "kQmoSXCVCaah"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_num_seq = len(text)//(seq_len+1)\n",
        "total_num_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwIKe8f5Cd5T",
        "outputId": "54937377-2c4b-4e34-8243-12a2f1eb76b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Training Sequences\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "\n",
        "for i in char_dataset.take(500):\n",
        "     print(ind_to_char[i.numpy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hEt83gFCpPm",
        "outputId": "e561b8e4-f5e2-4603-ebda-6a1c83686f20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metoda **batch** konwertuje te indywidualne wywołania znaków na sekwencje, które możemy wprowadzić jako batch.\n",
        "Używamy seq_len+1 z powodu zerowego indeksowania. Oto co oznacza\n",
        "\n",
        "\n",
        "drop_remainder: (Opcjonalnie.) `tf.bool` skalar `tf.Tensor`, reprezentujący czy ostatnia partia powinna zostać porzucona w przypadku, gdy ma mniej niż  `batch_size` elementów; domyślnym zachowaniem jest nieusuwanie mniejszej batch.\n",
        "    batch.\n"
      ],
      "metadata": {
        "id": "6iKewJnPD93i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "oR1bkPeNDXKK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teraz, gdy mamy już nasze sekwencje, wykonamy dla każdej z nich następujące kroki, aby utworzyć docelowe sekwencje tekstowe:\n",
        "\n",
        "1. podaj sekwencję tekstu wejściowego\n",
        "2. Przypisz docelową sekwencję tekstu jako sekwencję tekstu wejściowego przesuniętą o jeden krok do przodu\n",
        "3. Zgrupuj je razem w krotkę"
      ],
      "metadata": {
        "id": "9bof7eG-ElY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1]\n",
        "    target_txt = seq[1:]\n",
        "    return input_txt, target_txt"
      ],
      "metadata": {
        "id": "R-uVTFP4FZ2n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ],
      "metadata": {
        "id": "9QCc6KEXFjkk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_txt, target_txt in  dataset.take(1):\n",
        "    print(input_txt.numpy())\n",
        "    print(''.join(ind_to_char[input_txt.numpy()]))\n",
        "    print('\\n')\n",
        "    print(target_txt.numpy())\n",
        "    # There is an extra whitespace!\n",
        "    print(''.join(ind_to_char[target_txt.numpy()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZAAOIoTFr9e",
        "outputId": "0dd082cb-de3c-4347-88c0-77ba2f272989"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generowanie  szkoleniowych batch -ów\n",
        "\n",
        "Teraz, gdy mamy już rzeczywiste sekwencje, utworzymy batch. Chcemy potasować te sekwencje w losowej kolejności, aby model nie pasował do żadnej sekcji tekstu, ale zamiast tego mógł generować znaki na podstawie dowolnego tekstu początkowego."
      ],
      "metadata": {
        "id": "P3wHLIM1GoPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "batch_size = 128\n",
        "\n",
        "# Rozmiar bufora do przetasowania zbioru danych, tak aby nie próbował on przetasować\n",
        "# całej sekwencji w pamięci. Zamiast tego utrzymuje bufor, w którym tasuje elementy\n",
        "\n",
        "\n",
        "buffer_size = 10000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "yKDznFseHHGu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07_PHBczHd5e",
        "outputId": "a9c8b187-2af5-44fe-eb68-4aed9c2c09cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Utworzenie modelu**"
      ],
      "metadata": {
        "id": "IH8FL-CFIY-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Będziemy używać modelu opartego na LSTM z kilkoma dodatkowymi funkcjami, w tym warstwą osadzającą na początek i **dwoma** warstwami LSTM.\n",
        "\n",
        " Architekturę tego modelu oparliśmy na [DeepMoji](https://deepmoji.mit.edu/), a oryginalny kod źródłowy można znaleźć [tutaj](https://github.com/bfelbo/DeepMoji).\n",
        "\n",
        "Warstwa osadzająca będzie służyć jako warstwa wejściowa, która zasadniczo tworzy tabelę przeglądową, która odwzorowuje indeksy liczbowe każdego znaku na wektor z liczbą wymiarów „embedding dim”. Jak możesz sobie wyobrazić, im większy rozmiar osadzania, tym bardziej złożony jest trening. Jest to podobne do idei stojącej za word2vec, gdzie słowa są odwzorowywane w jakiejś n-wymiarowej przestrzeni. Osadzanie przed przesłaniem bezpośrednio do LSTM zwykle prowadzi do bardziej realistycznych wyników."
      ],
      "metadata": {
        "id": "9XhDGgycIcSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embed_dim = 64\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ],
      "metadata": {
        "id": "rUVt4480Ixcg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
      ],
      "metadata": {
        "id": "JckVis8hL63e"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Konfigurowanie funkcji straty\n",
        "\n",
        "Na naszą stratę użyjemy rzadkiej kategorycznej crossentropii, którą możemy zaimportować z Keras. Ustawimy to również jako logits=True"
      ],
      "metadata": {
        "id": "id1lAJ6XMOr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "metadata": {
        "id": "rLoHTxn8MKqq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(sparse_categorical_crossentropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gF2w61SMeEl",
        "outputId": "fc85fec3-df8c-40ae-e844-0e35fe00458e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sparse_categorical_crossentropy in module keras.src.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1, ignore_class=None)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Standalone usage:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss.numpy()\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "    \n",
            "    >>> y_true = [[[ 0,  2],\n",
            "    ...            [-1, -1]],\n",
            "    ...           [[ 0,  2],\n",
            "    ...            [-1, -1]]]\n",
            "    >>> y_pred = [[[[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]],\n",
            "    ...             [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]],\n",
            "    ...           [[[1.0, 0.0, 0.0], [0.0, 0.5, 0.5]],\n",
            "    ...            [[0.2, 0.5, 0.3], [0.0, 1.0, 0.0]]]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
            "    ...   y_true, y_pred, ignore_class=-1)\n",
            "    >>> loss.numpy()\n",
            "    array([[[2.3841855e-07, 2.3841855e-07],\n",
            "            [0.0000000e+00, 0.0000000e+00]],\n",
            "           [[2.3841855e-07, 6.9314730e-01],\n",
            "            [0.0000000e+00, 0.0000000e+00]]], dtype=float32)\n",
            "    \n",
            "    Args:\n",
            "        y_true: Ground truth values.\n",
            "        y_pred: The predicted values.\n",
            "        from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            "            default, we assume that `y_pred` encodes a probability distribution.\n",
            "        axis: Defaults to -1. The dimension along which the entropy is\n",
            "            computed.\n",
            "        ignore_class: Optional integer. The ID of a class to be ignored during\n",
            "            loss computation. This is useful, for example, in segmentation\n",
            "            problems featuring a \"void\" class (commonly -1 or 255) in\n",
            "            segmentation maps. By default (`ignore_class=None`), all classes are\n",
            "            considered.\n",
            "    \n",
            "    Returns:\n",
            "        Sparse categorical crossentropy loss value.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy\n"
      ],
      "metadata": {
        "id": "Ge2qeGv2MpP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ],
      "metadata": {
        "id": "m5g8RslsMjYd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Gated Recurrent Unit (GRU)\n",
        "# to rodzaj rekurencyjnej sieci neuronowej (RNN), która w niektórych przypadkach ma przewagę nad pamięcią długoterminową (LSTM).\n",
        "# GRU zużywa mniej pamięci i jest szybszy niż LSTM,\n",
        "# jednak LSTM jest dokładniejszy w przypadku korzystania ze zbiorów danych o dłuższych sekwencjach.\n",
        "\n",
        "\n",
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
        "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "    # Final Dense Layer to Predict\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
        "    return model"
      ],
      "metadata": {
        "id": "R3ydBSEDMx5F"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(\n",
        "  vocab_size = vocab_size,\n",
        "  embed_dim=embed_dim,\n",
        "  rnn_neurons=rnn_neurons,\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ub7W980WMzyl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH00-O-aM6U7",
        "outputId": "ca9186f5-42ff-4f1e-f868-8da918ea02e2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (128, None, 64)           5376      \n",
            "                                                                 \n",
            " gru (GRU)                   (128, None, 1026)         3361176   \n",
            "                                                                 \n",
            " dense (Dense)               (128, None, 84)           86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3452820 (13.17 MB)\n",
            "Trainable params: 3452820 (13.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trenowanie modelu\n",
        "\n",
        "Zanim spędzimy zbyt dużo czasu na szkoleniu, upewnijmy się, że wszystko jest w porządku z naszym modelem!\n",
        "\n",
        "Przekażmy partię, aby potwierdzić, że model obecnie przewiduje losowe znaki bez żadnego szkolenia."
      ],
      "metadata": {
        "id": "Ie0DfQyyNL0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  # Predict off some random batch\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "  # Display the dimensions of the predictions\n",
        "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0s7jkvwNXiD",
        "outputId": "281412fd-bf00-4431-95ec-5852d5fde31a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 120, 84)  <=== (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSnx2VFrNl1a",
        "outputId": "7b84e910-89ea-4658-fcb4-002a7d6e0883"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 120, 84), dtype=float32, numpy=\n",
              "array([[[ 2.0953121e-03,  1.1258886e-02, -2.5940579e-03, ...,\n",
              "         -1.2392533e-02, -3.4673782e-03, -7.2439230e-04],\n",
              "        [ 3.2578486e-03,  1.6974702e-02, -3.3724171e-03, ...,\n",
              "         -1.8630806e-02, -5.6052436e-03, -8.9238683e-04],\n",
              "        [ 3.2666810e-03,  7.0074308e-03,  8.6849194e-04, ...,\n",
              "         -9.1478936e-03, -6.6484632e-03, -9.7594662e-03],\n",
              "        ...,\n",
              "        [ 4.3208823e-03,  1.6876326e-03, -2.0872334e-03, ...,\n",
              "          1.0710944e-03, -3.4363889e-03, -1.4540803e-02],\n",
              "        [ 5.6978567e-03,  1.1195677e-02, -3.8253334e-03, ...,\n",
              "         -1.1791485e-02, -5.9310542e-03, -8.7070828e-03],\n",
              "        [ 6.9749728e-03,  1.2424210e-02, -1.0757009e-02, ...,\n",
              "         -2.5953290e-03,  7.5302966e-04, -2.6490067e-03]],\n",
              "\n",
              "       [[-1.6526725e-03, -5.7955598e-03, -3.4861043e-03, ...,\n",
              "          6.0472847e-03,  1.8851823e-03,  8.7492019e-03],\n",
              "        [ 1.5027629e-03,  6.6816565e-03, -2.8176974e-03, ...,\n",
              "         -9.6855760e-03, -2.0699296e-03,  3.3649746e-03],\n",
              "        [ 5.7576556e-04,  3.5231637e-03,  1.2273546e-03, ...,\n",
              "         -1.3937601e-02,  2.7568191e-03,  1.0076134e-02],\n",
              "        ...,\n",
              "        [ 6.4421026e-03,  3.0405009e-03,  2.5639094e-03, ...,\n",
              "         -5.7752752e-03,  6.8502640e-04,  3.2868262e-03],\n",
              "        [ 7.4683852e-03,  1.1360720e-02, -1.3397903e-03, ...,\n",
              "          5.9097860e-04,  3.6184355e-03,  3.7062954e-04],\n",
              "        [ 2.1547291e-03,  1.9277080e-03, -5.0011877e-04, ...,\n",
              "          2.2091435e-03,  3.3133118e-03, -2.9426985e-03]],\n",
              "\n",
              "       [[-2.0397421e-04,  9.6697151e-04,  1.5081605e-03, ...,\n",
              "         -8.7333666e-03,  3.9086575e-03,  8.4744291e-03],\n",
              "        [ 3.2615201e-03,  1.1944497e-02, -1.7832023e-03, ...,\n",
              "         -1.6639957e-02, -1.5209730e-03,  2.7843947e-03],\n",
              "        [ 4.1835718e-03,  2.8681627e-03,  6.2951739e-03, ...,\n",
              "         -6.6108368e-03, -6.4493954e-04,  7.9183299e-03],\n",
              "        ...,\n",
              "        [ 2.4805551e-03,  1.3690018e-02, -3.6038631e-03, ...,\n",
              "         -1.7034410e-02,  8.5800828e-04,  2.3767741e-03],\n",
              "        [ 3.2397432e-03,  4.0922076e-03,  5.0896681e-03, ...,\n",
              "         -6.8954742e-03,  1.0461466e-03,  8.2506668e-03],\n",
              "        [ 5.1509887e-03,  1.2009726e-02,  3.5436027e-04, ...,\n",
              "          6.5055583e-04,  4.7598630e-03,  3.8327414e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 2.0953121e-03,  1.1258886e-02, -2.5940579e-03, ...,\n",
              "         -1.2392533e-02, -3.4673782e-03, -7.2439230e-04],\n",
              "        [ 5.9689712e-03,  9.8691899e-03, -2.5045546e-03, ...,\n",
              "         -5.2340114e-03, -9.4822068e-03, -2.4204173e-04],\n",
              "        [ 5.7883374e-03,  7.8391470e-03, -2.8958003e-04, ...,\n",
              "         -1.0125595e-03, -7.0506586e-03, -1.0767776e-02],\n",
              "        ...,\n",
              "        [ 4.6951110e-03,  3.4350441e-03,  4.9588722e-03, ...,\n",
              "         -5.7144240e-03, -4.9532568e-03, -3.0751382e-03],\n",
              "        [ 5.1882965e-03,  8.3737317e-03, -6.8496573e-03, ...,\n",
              "          3.6418092e-04,  2.9144045e-03,  5.7367451e-04],\n",
              "        [ 5.9154551e-03,  4.1560670e-03, -4.5055249e-03, ...,\n",
              "         -2.2533603e-03,  7.7249310e-03,  4.8903399e-03]],\n",
              "\n",
              "       [[-6.0726441e-03, -4.4981414e-03,  1.3277238e-03, ...,\n",
              "         -2.6466555e-03,  2.0715916e-03, -9.8383556e-05],\n",
              "        [-1.4640713e-03,  2.3691312e-03,  1.1121292e-03, ...,\n",
              "         -9.9381607e-04, -2.3561598e-04, -1.0470472e-02],\n",
              "        [ 1.4705621e-03,  1.2115943e-02, -1.1958721e-03, ...,\n",
              "         -1.3276490e-02, -3.4498454e-03, -6.7953817e-03],\n",
              "        ...,\n",
              "        [ 6.4982367e-03,  8.6756153e-03, -1.3376391e-03, ...,\n",
              "         -5.0720922e-03, -9.7329933e-03, -1.8535157e-04],\n",
              "        [ 8.3175302e-03,  1.3513471e-02, -1.7800768e-03, ...,\n",
              "          1.0029802e-03, -1.2014668e-03, -2.2198306e-03],\n",
              "        [ 7.1511553e-03,  1.0141639e-02,  6.2934426e-04, ...,\n",
              "         -4.1167028e-03, -3.4116539e-03, -1.7064482e-03]],\n",
              "\n",
              "       [[ 2.0953121e-03,  1.1258886e-02, -2.5940579e-03, ...,\n",
              "         -1.2392533e-02, -3.4673782e-03, -7.2439230e-04],\n",
              "        [ 3.2578486e-03,  1.6974702e-02, -3.3724171e-03, ...,\n",
              "         -1.8630806e-02, -5.6052436e-03, -8.9238683e-04],\n",
              "        [ 3.8843134e-03,  1.9976899e-02, -3.5080058e-03, ...,\n",
              "         -2.1697156e-02, -6.8764812e-03, -9.8633824e-04],\n",
              "        ...,\n",
              "        [ 4.7901864e-03,  1.1841118e-02, -1.2361724e-03, ...,\n",
              "         -1.1602248e-02, -2.8561230e-03,  1.9437424e-03],\n",
              "        [ 7.2291284e-03,  1.0357605e-02, -4.2382305e-04, ...,\n",
              "         -4.8137116e-03, -9.5856516e-03,  7.8985948e-05],\n",
              "        [ 5.6698588e-03, -5.0778378e-04,  1.4567180e-03, ...,\n",
              "         -3.7242149e-03, -9.3767904e-03, -1.0063664e-02]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ],
      "metadata": {
        "id": "88ALAkSBNuVK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21izGRU_NwLh",
        "outputId": "08e6da82-4c63-4def-f42a-ba3a2b98c7ce"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[52],\n",
              "       [70],\n",
              "       [46],\n",
              "       [29],\n",
              "       [74],\n",
              "       [18],\n",
              "       [57],\n",
              "       [53],\n",
              "       [76],\n",
              "       [34],\n",
              "       [15],\n",
              "       [ 5],\n",
              "       [63],\n",
              "       [56],\n",
              "       [55],\n",
              "       [43],\n",
              "       [70],\n",
              "       [81],\n",
              "       [ 0],\n",
              "       [54],\n",
              "       [ 8],\n",
              "       [ 0],\n",
              "       [ 2],\n",
              "       [26],\n",
              "       [15],\n",
              "       [12],\n",
              "       [29],\n",
              "       [46],\n",
              "       [37],\n",
              "       [58],\n",
              "       [18],\n",
              "       [16],\n",
              "       [28],\n",
              "       [32],\n",
              "       [41],\n",
              "       [10],\n",
              "       [71],\n",
              "       [42],\n",
              "       [20],\n",
              "       [68],\n",
              "       [18],\n",
              "       [29],\n",
              "       [22],\n",
              "       [11],\n",
              "       [64],\n",
              "       [ 1],\n",
              "       [14],\n",
              "       [ 1],\n",
              "       [61],\n",
              "       [54],\n",
              "       [12],\n",
              "       [56],\n",
              "       [ 6],\n",
              "       [32],\n",
              "       [ 8],\n",
              "       [47],\n",
              "       [44],\n",
              "       [16],\n",
              "       [ 4],\n",
              "       [47],\n",
              "       [72],\n",
              "       [ 6],\n",
              "       [75],\n",
              "       [25],\n",
              "       [61],\n",
              "       [22],\n",
              "       [12],\n",
              "       [47],\n",
              "       [61],\n",
              "       [25],\n",
              "       [41],\n",
              "       [ 0],\n",
              "       [80],\n",
              "       [23],\n",
              "       [81],\n",
              "       [10],\n",
              "       [ 8],\n",
              "       [33],\n",
              "       [56],\n",
              "       [16],\n",
              "       [59],\n",
              "       [60],\n",
              "       [14],\n",
              "       [50],\n",
              "       [30],\n",
              "       [34],\n",
              "       [16],\n",
              "       [ 3],\n",
              "       [39],\n",
              "       [58],\n",
              "       [11],\n",
              "       [76],\n",
              "       [68],\n",
              "       [ 5],\n",
              "       [61],\n",
              "       [75],\n",
              "       [14],\n",
              "       [33],\n",
              "       [73],\n",
              "       [15],\n",
              "       [77],\n",
              "       [46],\n",
              "       [66],\n",
              "       [67],\n",
              "       [57],\n",
              "       [13],\n",
              "       [78],\n",
              "       [13],\n",
              "       [46],\n",
              "       [62],\n",
              "       [79],\n",
              "       [52],\n",
              "       [75],\n",
              "       [29],\n",
              "       [59],\n",
              "       [33],\n",
              "       [35],\n",
              "       [11],\n",
              "       [72],\n",
              "       [24]])>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reformat to not be a lists of lists\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "ln6ZKbcCN4rp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0neynoQN6Iu",
        "outputId": "5b005b27-26f3-40ee-d529-3b91ee30b602"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([52, 70, 46, 29, 74, 18, 57, 53, 76, 34, 15,  5, 63, 56, 55, 43, 70,\n",
              "       81,  0, 54,  8,  0,  2, 26, 15, 12, 29, 46, 37, 58, 18, 16, 28, 32,\n",
              "       41, 10, 71, 42, 20, 68, 18, 29, 22, 11, 64,  1, 14,  1, 61, 54, 12,\n",
              "       56,  6, 32,  8, 47, 44, 16,  4, 47, 72,  6, 75, 25, 61, 22, 12, 47,\n",
              "       61, 25, 41,  0, 80, 23, 81, 10,  8, 33, 56, 16, 59, 60, 14, 50, 30,\n",
              "       34, 16,  3, 39, 58, 11, 76, 68,  5, 61, 75, 14, 33, 73, 15, 77, 46,\n",
              "       66, 67, 57, 13, 78, 13, 46, 62, 79, 52, 75, 29, 59, 33, 35, 11, 72,\n",
              "       24])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JPvxNi6N_iO",
        "outputId": "11b6a933-4058-4609-9f8b-a45f140c6128"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the input seq: \n",
            "\n",
            "  A leg of Rome shall not return to tell\n",
            "    What crows have peck'd them here. He brags his service,\n",
            "    As if he were o\n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "[oUDs7b]uI4'ha`Roz\n",
            "_,\n",
            "!A41DULc75CGP.pQ9m7D;0i 3 f_1a(G,VS5&Vq(t?f;1Vf?P\n",
            "y<z.,Ha5de3YEI5\"Nc0um'ft3Hr4vUklb2w2Ugx[tDdHJ0q>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Po potwierdzeniu, że wymiary działają, przeszkolmy naszą sieć!"
      ],
      "metadata": {
        "id": "nHnVEzZPOJ3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30"
      ],
      "metadata": {
        "id": "TZ2C62fxOWRK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Procesor T4 GPU - 30 minut\n",
        "model.fit(dataset,epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pgsOWZrOQKU",
        "outputId": "2cb753d3-ed93-46c6-f5fb-32a983ec219f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "351/351 [==============================] - 51s 125ms/step - loss: 2.5313\n",
            "Epoch 2/30\n",
            "351/351 [==============================] - 51s 123ms/step - loss: 1.7128\n",
            "Epoch 3/30\n",
            "351/351 [==============================] - 47s 125ms/step - loss: 1.4456\n",
            "Epoch 4/30\n",
            "351/351 [==============================] - 47s 127ms/step - loss: 1.3306\n",
            "Epoch 5/30\n",
            "351/351 [==============================] - 49s 129ms/step - loss: 1.2696\n",
            "Epoch 6/30\n",
            "351/351 [==============================] - 46s 125ms/step - loss: 1.2305\n",
            "Epoch 7/30\n",
            "351/351 [==============================] - 47s 128ms/step - loss: 1.2019\n",
            "Epoch 8/30\n",
            "351/351 [==============================] - 46s 124ms/step - loss: 1.1782\n",
            "Epoch 9/30\n",
            "351/351 [==============================] - 47s 128ms/step - loss: 1.1584\n",
            "Epoch 10/30\n",
            "351/351 [==============================] - 46s 124ms/step - loss: 1.1418\n",
            "Epoch 11/30\n",
            "351/351 [==============================] - 47s 128ms/step - loss: 1.1259\n",
            "Epoch 12/30\n",
            "351/351 [==============================] - 46s 124ms/step - loss: 1.1120\n",
            "Epoch 13/30\n",
            "351/351 [==============================] - 47s 123ms/step - loss: 1.0989\n",
            "Epoch 14/30\n",
            "351/351 [==============================] - 47s 127ms/step - loss: 1.0866\n",
            "Epoch 15/30\n",
            "351/351 [==============================] - 47s 129ms/step - loss: 1.0747\n",
            "Epoch 16/30\n",
            "351/351 [==============================] - 48s 130ms/step - loss: 1.0639\n",
            "Epoch 17/30\n",
            "351/351 [==============================] - 48s 131ms/step - loss: 1.0532\n",
            "Epoch 18/30\n",
            "351/351 [==============================] - 48s 132ms/step - loss: 1.0436\n",
            "Epoch 19/30\n",
            "351/351 [==============================] - 46s 126ms/step - loss: 1.0344\n",
            "Epoch 20/30\n",
            "351/351 [==============================] - 48s 129ms/step - loss: 1.0258\n",
            "Epoch 21/30\n",
            "351/351 [==============================] - 46s 125ms/step - loss: 1.0174\n",
            "Epoch 22/30\n",
            "351/351 [==============================] - 47s 128ms/step - loss: 1.0104\n",
            "Epoch 23/30\n",
            "351/351 [==============================] - 46s 124ms/step - loss: 1.0036\n",
            "Epoch 24/30\n",
            "351/351 [==============================] - 47s 128ms/step - loss: 0.9972\n",
            "Epoch 25/30\n",
            "351/351 [==============================] - 46s 124ms/step - loss: 0.9918\n",
            "Epoch 26/30\n",
            "351/351 [==============================] - 47s 123ms/step - loss: 0.9866\n",
            "Epoch 27/30\n",
            "351/351 [==============================] - 48s 127ms/step - loss: 0.9820\n",
            "Epoch 28/30\n",
            "351/351 [==============================] - 47s 129ms/step - loss: 0.9783\n",
            "Epoch 29/30\n",
            "351/351 [==============================] - 48s 130ms/step - loss: 0.9745\n",
            "Epoch 30/30\n",
            "351/351 [==============================] - 48s 131ms/step - loss: 0.9718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bd23a42ef20>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generowanie tekstu\n",
        "\n",
        "Obecnie nasz model oczekuje tylko 128 sekwencji na raz. Możemy utworzyć nowy model, który oczekuje tylko rozmiaru partii = 1. Możemy utworzyć nowy model o tej wielkości partii, a następnie załadować zapisane wagi modeli. Następnie wywołaj .build() na modelu:\n",
        "\n"
      ],
      "metadata": {
        "id": "H1OYxYC_OkEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/dane/modele/shakespeare_gen.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwqQ_5REPwqG",
        "outputId": "9e3b3e53-d240-42ab-d86f-75cc508313d2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "3KhqpaYWP5ye"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "\n",
        "model.load_weights('/content/drive/MyDrive/dane/modele/shakespeare_gen.h5')\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "q0SxRydBP6_7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5ER7e66P_3M",
        "outputId": "b6e9e669-cbef-4b62-dbc1-644caf7cf2d1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (1, None, 64)             5376      \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (1, None, 1026)           3361176   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (1, None, 84)             86268     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3452820 (13.17 MB)\n",
            "Trainable params: 3452820 (13.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "  '''\n",
        "  model: Trained Model to Generate Text\n",
        "  start_seed: Intial Seed text in string form\n",
        "  gen_size: Number of characters to generate\n",
        "\n",
        "  Basic idea behind this function is to take in some seed text, format it so\n",
        "  that it is in the correct shape for our network, then loop the sequence as\n",
        "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
        "  time series problems.\n",
        "  '''\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = gen_size\n",
        "\n",
        "  # Vecotrizing starting seed text\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "\n",
        "  # Expand to match batch format shape\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty list to hold resulting generated text\n",
        "  text_generated = []\n",
        "\n",
        "  # Temperature effects randomness in our resulting text\n",
        "  # The term is derived from entropy/thermodynamics.\n",
        "  # The temperature is used to effect probability of next characters.\n",
        "  # Higher probability == lesss surprising/ more expected\n",
        "  # Lower temperature == more surprising / less expected\n",
        "\n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "\n",
        "      # Generate Predictions\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      # Remove the batch shape dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # Use a cateogircal disitribution to select the next character\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # Pass the predicted charracter for the next input\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      # Transform back to character letter\n",
        "      text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "1f9TDQ5WQExS"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"From fairest creatures we\",gen_size=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWDAYgXsQKED",
        "outputId": "fa6fc5e2-d5c3-452f-a6e3-eaf5e36974e3"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From fairest creatures well;\n",
            "    Old Gaunt, sweet Nay, I bid him speak things?\n",
            "  OLICKA. Would you do it without that neither\n"
          ]
        }
      ]
    }
  ]
}