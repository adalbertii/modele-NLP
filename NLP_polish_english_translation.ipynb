{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Io98erch0vt-dokDXIIqqeSh0t-KRVEB",
      "authorship_tag": "ABX9TyNBoIW8Yn2Rfem1g3iUKzCW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/modele-NLP/blob/main/NLP_polish_english_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackabuse.com/python-for-nlp-neural-machine-translation-with-seq2seq-in-keras/\n"
      ],
      "metadata": {
        "id": "MTnCw8pbo91F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dm67yEZZk2qQ"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "LSTM_NODES =256\n",
        "NUM_SENTENCES = 20000\n",
        "MAX_SENTENCE_LENGTH = 50\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_SIZE = 100"
      ],
      "metadata": {
        "id": "2kV7jYIelA3u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "\n",
        "count = 0\n",
        "for line in open(r'/content/drive/MyDrive/dane/pol.txt', encoding=\"utf-8\"):\n",
        "    count += 1\n",
        "\n",
        "    if count > NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "    if '\\t' not in line:\n",
        "        continue\n",
        "\n",
        "    input_sentence, output, _ = line.rstrip().split('\\t')\n",
        "\n",
        "    output_sentence = output + ' <eos>'\n",
        "    output_sentence_input = '<sos> ' + output\n",
        "\n",
        "    input_sentences.append(input_sentence)\n",
        "    output_sentences.append(output_sentence)\n",
        "    output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "print(\"num samples input:\", len(input_sentences))\n",
        "print(\"num samples output:\", len(output_sentences))\n",
        "print(\"num samples output input:\", len(output_sentences_inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA6S-8ItlDpf",
        "outputId": "34c454c9-9976-4095-c69a-c431ae9d6ed4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num samples input: 20000\n",
            "num samples output: 20000\n",
            "num samples output input: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYZe8IY0nC-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_sentences[172])\n",
        "print(output_sentences[172])\n",
        "print(output_sentences_inputs[172])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osId7rEVm8Ts",
        "outputId": "54be6502-d528-4da5-9414-c6d9a9f82e9b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hold it.\n",
            "Trzymaj je. <eos>\n",
            "<sos> Trzymaj je.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Length of longest sentence in input: %g\" % max_input_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N_FWvG9nDhi",
        "outputId": "e5af4f4d-072c-47a9-916f-bc8114bf53f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words in the input: 4587\n",
            "Length of longest sentence in input: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWxcpGbinL4O",
        "outputId": "51820a26-ed2a-4160-b062-e5949a3f8c30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words in the output: 13446\n",
            "Length of longest sentence in the output: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences.shape:\", encoder_input_sequences.shape)\n",
        "print(\"encoder_input_sequences[172]:\", encoder_input_sequences[172])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L93Slot1nSo6",
        "outputId": "b549199c-0635-4bd0-b132-7ab1e2db2111"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input_sequences.shape: (20000, 7)\n",
            "encoder_input_sequences[172]: [  0   0   0   0   0 351   7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2idx_inputs[\"i'm\"])\n",
        "print(word2idx_inputs[\"ill\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P55TaF6nYFt",
        "outputId": "33d1cc13-0f49-424a-9b36-2bd6be8c4afa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)\n",
        "print(\"decoder_input_sequences[172]:\", decoder_input_sequences[172])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnT0Qi4ZnfrM",
        "outputId": "6abd66b1-f082-4733-f463-fc6b17268900"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoder_input_sequences.shape: (20000, 11)\n",
            "decoder_input_sequences[172]: [  2 277 214   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word2idx_outputs[\"<sos>\"])\n",
        "print(word2idx_outputs[\"je\"])\n",
        "print(word2idx_outputs[\"suis\"])\n",
        "print(word2idx_outputs[\"malade.\"])"
      ],
      "metadata": {
        "id": "MSEGCTMZoRX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8i7bBCKoSlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open(r'/content/drive/My Drive/datasets/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "metadata": {
        "id": "zGl9PAUMoXoP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}