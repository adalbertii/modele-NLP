{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/adalbertii/modele-NLP/blob/main/Embedding_01.ipynb",
      "authorship_tag": "ABX9TyP0l8dmjufMVOdcSTjM678U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/modele-NLP/blob/main/Embedding_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3D8Zm0MLH15R"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Budowanie warstwy Embedding dla słownika składającego się z 10 cyfr**\n",
        "\n",
        "Bez procesu uczenia"
      ],
      "metadata": {
        "id": "mz06_Mqv_t_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# utworzenie prostego modelu z warstwą Embedding\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(input_dim=10,output_dim=4,input_length=2)\n",
        "model.add(embedding_layer)\n",
        "model.compile('adam','mse')\n",
        "\n",
        "# input_dim - rozmiar słownika\n",
        "# output_dim - długość wektora dla  każdego słowa\n",
        "# input_length - maksymalna długość sekwencji\n",
        "\n",
        "# W powyższym przykładzie ustawiamy 10 jako rozmiar słownictwa, ponieważ będziemy kodować liczby od 0 do 9.\n",
        "# Chcemy, aby długość wektora słów wynosiła 4, stąd output_dim jest ustawione na 4.\n",
        "# Długość sekwencji wejściowej do warstwy osadzania będzie wynosić 2 (będziemy podawać na wejściu sieci dwie cyfry)"
      ],
      "metadata": {
        "id": "POU5qXfQIKfF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "05FrbPgKAK1-",
        "outputId": "aefa3238-74ec-4602-8f3c-50ca8da2b8dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 2, 4)              40        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40 (160.00 Byte)\n",
            "Trainable params: 40 (160.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wydruk wspólczynników wagowych warstwy Embedding\n",
        "# Poniewaćż nie inicjujemy procesu uczenia wartości wag są losowe\n",
        "\n",
        "print(model.weights)"
      ],
      "metadata": {
        "id": "YJlcJUGRAUXQ",
        "outputId": "44af7a81-60a6-4c39-a281-c78a7d3424e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'embedding/embeddings:0' shape=(10, 4) dtype=float32, numpy=\n",
            "array([[ 0.04904598,  0.01858591, -0.02007126, -0.02552595],\n",
            "       [-0.02946062, -0.02123396,  0.03412256, -0.00302137],\n",
            "       [-0.02394114, -0.02776796, -0.0345423 , -0.00422161],\n",
            "       [ 0.02900541,  0.0168095 , -0.00106485, -0.0067815 ],\n",
            "       [ 0.02968682, -0.04740422, -0.00162083, -0.00240406],\n",
            "       [-0.02717358,  0.03190272, -0.04689808, -0.03944625],\n",
            "       [ 0.0435021 ,  0.03977196,  0.04693612,  0.03889617],\n",
            "       [-0.02779729,  0.00850797,  0.04949093, -0.03497918],\n",
            "       [ 0.01109295,  0.01071211, -0.02503854, -0.04367982],\n",
            "       [-0.02446722,  0.03542474, -0.02460161, -0.02766456]],\n",
            "      dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Te wagi są reprezentacjami wektorowymi słów w słownictwie.\n",
        "Tabela wag o rozmiarze 10 x 4, dla słów od 0 do 9.\n"
      ],
      "metadata": {
        "id": "I-AX-B2SEHm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Teraz przekażmy przykładowe dane wejściowe do  modelu i zobaczmy wyniki.\n",
        "input_data = np.array([[1,2]])\n",
        "pred = model.predict(input_data)\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dane wejściowe modelu:\", input_data.shape)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"\")\n",
        "print(\"Wartości wag warstwy Embedding dla podanych na wejsciu danych:\")\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy4pcRPlJXEA",
        "outputId": "4561beb5-2772-4b34-fce9-5db4a160d29b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "-----------------------------------------------------------------\n",
            "Dane wejściowe modelu: (1, 2)\n",
            "-----------------------------------------------------------------\n",
            "\n",
            "Wartości wag warstwy Embedding dla podanych na wejsciu danych:\n",
            "[[[-0.02946062 -0.02123396  0.03412256 -0.00302137]\n",
            "  [-0.02394114 -0.02776796 -0.0345423  -0.00422161]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jak widać, każde słowo (1 i 2) jest reprezentowane przez wektor o długości 4."
      ],
      "metadata": {
        "id": "40b5QDksJuXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "W tym przykładzie nie wytrenowaliśmy warstwy osadzania. Wagi przypisane do wektorów słów są inicjowane losowo."
      ],
      "metadata": {
        "id": "iiYcMjV0K2U2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Klasyfikacja recenzji restauracji**\n",
        "\n",
        "\n",
        "Tok działań:    \n",
        "*   Tokenizacja zdań na słowa.\n",
        "*   Utwórzenie zakodowanego wektor \"one-hot\" dla każdego słowa.\n",
        "*   Użycie funkcji \"Padding\", w celu ujednolicenia rozmiaru sekekwencji wejściowej modelu (upewnienia się, że wszystkie sekwencje mają tę samą długość).\n",
        "*   Przekazanie wypełnionych sekwencji jako danych wejściowwych do warstwy Embedding.\n",
        "*   Spłaszczennie danych do wktora i zastostosowanie  warstwę Dense, aby przewidywać etykietę\n",
        "\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "OZAUMIRlVF3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Embedding,Dense"
      ],
      "metadata": {
        "id": "SGtqray1K1fP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aby to uprościć, użyjemy łącznie tylko  10 przykładowych, prostych  recenzji. Połowa z nich jest pozytywna, reprezentowana przez 0, a druga połowa jest negatywna, reprezentowana przez 1."
      ],
      "metadata": {
        "id": "pEjyX81-WjuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#definicja 10 recencji\n",
        "reviews =[\n",
        "          'Never coming back!',\n",
        "          'horrible service',\n",
        "          'rude waitress',\n",
        "          'cold food',\n",
        "          'horrible food!',\n",
        "          'awesome',\n",
        "          'awesome services!',\n",
        "          'rocks',\n",
        "          'poor work',\n",
        "          'couldn\\'t have done better'\n",
        "]\n",
        "\n",
        "#definicja etykiet (1-negatywane, 0-pozytywna)\n",
        "labels = array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "metadata": {
        "id": "OiQT-Ga8WaZi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przyjmiemy rozmiar słownictwa jako 50 i zakodujemy słowa za pomocą funkcji \"one_hot\" z Keras."
      ],
      "metadata": {
        "id": "y9ViQAMNu_0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Vocab_size = 50\n",
        "encoded_reviews = [one_hot(d,Vocab_size) for d in reviews]\n",
        "print(f'encoded reviews: {encoded_reviews}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up1N-FAjW2em",
        "outputId": "c5806d40-4298-42b3-af33-ed89fb135430"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded reviews: [[36, 48, 19], [36, 48], [8, 4], [40, 49], [36, 49], [12], [12, 9], [48], [17, 45], [10, 28, 7, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Widać, że długość każdej zakodowanej recenzji jest równa liczbie słów w tej recenzji. Keras one_hot  konwertuje każde słowo na zakodowany indeks one-hot.\n",
        "\n",
        "Teraz musimy zastosować \"padding\", aby wszystkie zakodowane recenzje miały tę samą długość.\n",
        "\n",
        "Zdefiniujmy 4 jako maksymalną długość i wypełnijmy zakodowane wektory zerami na końcu."
      ],
      "metadata": {
        "id": "KlAF6u8JvnEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "padded_reviews = pad_sequences(encoded_reviews,maxlen=max_length,padding='post')\n",
        "print(padded_reviews)\n",
        "\n",
        "#Wypełnione i zakodowane recenzje będą wyglądać następująco:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCsGqQn7v0Ug",
        "outputId": "009f5009-5b37-4de7-8cf1-ec068e8dd145"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[36 48 19  0]\n",
            " [36 48  0  0]\n",
            " [ 8  4  0  0]\n",
            " [40 49  0  0]\n",
            " [36 49  0  0]\n",
            " [12  0  0  0]\n",
            " [12  9  0  0]\n",
            " [48  0  0  0]\n",
            " [17 45  0  0]\n",
            " [10 28  7 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Po utworzeniu ujednoliconej pod względem rozmiaru, zakodowanje  reprezentacji recenzji, jesteśmy gotowi do przekazania jej jako danych wejściowych do warstwy osadzania.\n",
        "\n",
        "W poniższym fragmencie kodu tworzymy prosty model Keras.\n",
        "\n",
        "Ustalimy arbitralnie długość osadzonych wektorów dla każdego słowa na 8, a długość wejściowa będzie maksymalną długością, którą już zdefiniowaliśmy jako 4."
      ],
      "metadata": {
        "id": "tORfLAZlwWjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(input_dim=Vocab_size,output_dim=8,input_length=max_length, name=\"wmi-embedding\")"
      ],
      "metadata": {
        "id": "ZMpvLiokGPWc"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])"
      ],
      "metadata": {
        "id": "12Tn92XCwlM3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcIRcE_swypf",
        "outputId": "093cd7cb-3c7e-4b51-8f84-9af6f8669105"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 4, 8)              400       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 433 (1.69 KB)\n",
            "Trainable params: 433 (1.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Proces uczenia zdefiniowanego modelu**"
      ],
      "metadata": {
        "id": "PL6nM8R5w6PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(padded_reviews,labels,epochs=30,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8foLJOqw_Ez",
        "outputId": "6b18c193-3f32-44df-e8eb-32889f8225d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 588ms/step - loss: 0.6907 - acc: 0.5000\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6892 - acc: 0.6000\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6877 - acc: 0.6000\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6862 - acc: 0.6000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6846 - acc: 0.6000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6831 - acc: 0.6000\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6816 - acc: 0.6000\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6801 - acc: 0.7000\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6786 - acc: 0.7000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6771 - acc: 0.8000\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6756 - acc: 0.8000\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6740 - acc: 0.8000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6725 - acc: 0.8000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.8000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6694 - acc: 0.8000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6679 - acc: 0.9000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6663 - acc: 0.9000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6647 - acc: 1.0000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6632 - acc: 1.0000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6616 - acc: 1.0000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6600 - acc: 1.0000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6584 - acc: 1.0000\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6568 - acc: 1.0000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6551 - acc: 1.0000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6535 - acc: 1.0000\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6518 - acc: 1.0000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6502 - acc: 1.0000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6485 - acc: 1.0000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6468 - acc: 1.0000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6451 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b349b408130>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Po zakończeniu treningu warstwa osadzania nauczyła się wag, które są niczym innym jak reprezentacjami wektorowymi każdego słowa. Sprawdźmy kształt macierzy wag."
      ],
      "metadata": {
        "id": "iqvL6jc9xJTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.get_weights()[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI_6y1jVxOU0",
        "outputId": "944ad0b1-95cc-44dc-ea20-f61ba7e77852"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jeśli sprawdzimy osadzenie dla pierwszego słowa, otrzymamy następujący wektor.\n",
        "embedding_layer.get_weights()[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLvMro9ExWI7",
        "outputId": "35d849ce-1575-4284-88e0-bb4feb66db2a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.04851203, -0.11075204,  0.10378705,  0.05636813,  0.05719429,\n",
              "       -0.07346848, -0.16577914, -0.10423633], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_layer('wmi-embedding').get_weights()[0]\n",
        "weights"
      ],
      "metadata": {
        "id": "PgY1F_1lYjYG",
        "outputId": "0c43fd64-5da2-41a0-def0-7c7774b6e59e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04851203, -0.11075204,  0.10378705,  0.05636813,  0.05719429,\n",
              "        -0.07346848, -0.16577914, -0.10423633],\n",
              "       [ 0.00298854,  0.01044493,  0.02287051, -0.03371505, -0.00474351,\n",
              "        -0.04846238,  0.04859843,  0.04726615],\n",
              "       [ 0.0126707 ,  0.01779891, -0.02174922,  0.04905101, -0.00167285,\n",
              "        -0.03911553,  0.0147979 , -0.00747634],\n",
              "       [-0.01913589, -0.01298629,  0.00604038,  0.01522937, -0.03617267,\n",
              "         0.01281073,  0.00749461, -0.00292525],\n",
              "       [-0.11054561,  0.13014543, -0.08662777, -0.12499596, -0.07589606,\n",
              "         0.12794085,  0.14441918,  0.1304295 ],\n",
              "       [ 0.03123878, -0.03851577,  0.00698046, -0.0079921 ,  0.00209995,\n",
              "         0.04975987, -0.01187881,  0.0011056 ],\n",
              "       [-0.01686465, -0.036445  ,  0.0448685 , -0.04299518,  0.04232055,\n",
              "         0.02577514, -0.01014434, -0.02579236],\n",
              "       [-0.09814645,  0.07409479,  0.08487518, -0.05488968, -0.07794409,\n",
              "        -0.15437928, -0.11737133,  0.09343459],\n",
              "       [-0.05286421, -0.14167976,  0.05253988,  0.14375849, -0.07407774,\n",
              "        -0.07316174,  0.08721292,  0.12857206],\n",
              "       [ 0.14758287, -0.13619637,  0.12161121,  0.06739821,  0.09850444,\n",
              "        -0.17058104, -0.09802897, -0.1270638 ],\n",
              "       [ 0.06532185,  0.13503312, -0.14638239, -0.08505345,  0.04948474,\n",
              "         0.14274564, -0.05975633, -0.04795158],\n",
              "       [-0.00371056, -0.03978226, -0.0187786 , -0.0104256 , -0.00810176,\n",
              "         0.01924774,  0.04758788,  0.00994543],\n",
              "       [ 0.13877092,  0.09661142, -0.11084381, -0.15576373,  0.13938767,\n",
              "         0.08897563, -0.14424461, -0.14399114],\n",
              "       [ 0.01777938, -0.04310844, -0.01637179,  0.00942753,  0.01493707,\n",
              "         0.01203805,  0.03459612,  0.03004013],\n",
              "       [ 0.01191298,  0.0301508 , -0.01148554, -0.01803706,  0.03675941,\n",
              "         0.0441235 ,  0.03286288,  0.00279976],\n",
              "       [-0.04367621,  0.03899525, -0.01598672,  0.01591749, -0.00362506,\n",
              "        -0.02071732,  0.03259817,  0.00683762],\n",
              "       [-0.03892399,  0.03850633,  0.04385891,  0.01550158,  0.02063857,\n",
              "         0.03286285,  0.04884667, -0.04246625],\n",
              "       [ 0.12660655,  0.14542073, -0.07488345, -0.10329139,  0.11218343,\n",
              "         0.11079828, -0.15268022, -0.13482158],\n",
              "       [ 0.02374119, -0.04133616,  0.02249798,  0.0270929 , -0.01268699,\n",
              "         0.01719934, -0.02698828,  0.03396643],\n",
              "       [ 0.14195088, -0.13814604, -0.10030517,  0.09391663,  0.0968046 ,\n",
              "         0.12714116,  0.08030633, -0.10891496],\n",
              "       [ 0.02551376, -0.00140408,  0.00582713, -0.01079625, -0.03724496,\n",
              "        -0.03131463,  0.0386196 ,  0.02146754],\n",
              "       [-0.03244909, -0.00353459, -0.01876886, -0.02737047, -0.04611284,\n",
              "        -0.00186533,  0.03056834,  0.04947399],\n",
              "       [-0.04600345, -0.04669159,  0.03606901,  0.00207366, -0.02412865,\n",
              "         0.04504125, -0.00409539, -0.0098274 ],\n",
              "       [ 0.00945663,  0.01473883, -0.00269264,  0.00362278, -0.02262839,\n",
              "         0.00329666,  0.02717996, -0.01923511],\n",
              "       [-0.04259288,  0.01713933, -0.03265089,  0.02332171, -0.04236022,\n",
              "        -0.03034389,  0.04446887, -0.00438666],\n",
              "       [-0.00239   ,  0.04852447,  0.03883343,  0.02651033, -0.03297993,\n",
              "         0.02983285, -0.02940595, -0.00295386],\n",
              "       [-0.0323621 ,  0.00999584,  0.04072812, -0.04907004,  0.0444313 ,\n",
              "         0.00105818, -0.00084523, -0.00225819],\n",
              "       [-0.03723546,  0.0317493 , -0.02624241,  0.03879032,  0.0006503 ,\n",
              "         0.04144986, -0.03943519, -0.03691598],\n",
              "       [ 0.08772585, -0.15648274,  0.11554581,  0.14047453,  0.13927615,\n",
              "        -0.08023241, -0.06146593, -0.11389779],\n",
              "       [-0.02522497,  0.00975832, -0.03012292, -0.00827063, -0.04588993,\n",
              "         0.03630617, -0.03979958,  0.04055032],\n",
              "       [-0.02821001, -0.02282443, -0.01607443,  0.04223684,  0.01463446,\n",
              "         0.03687383, -0.0078528 ,  0.0359369 ],\n",
              "       [ 0.02273494,  0.02691634,  0.03426549, -0.0460443 ,  0.01644239,\n",
              "         0.00802406,  0.00036814,  0.03675617],\n",
              "       [ 0.02418904, -0.00903948,  0.04851038,  0.03783497, -0.03668373,\n",
              "        -0.02864641, -0.02890414, -0.01520365],\n",
              "       [-0.03454974, -0.04950653,  0.01326561,  0.01330418, -0.0459584 ,\n",
              "        -0.00028592,  0.0204708 ,  0.00556841],\n",
              "       [-0.01408152,  0.03914021, -0.03602026,  0.03850639,  0.02891323,\n",
              "         0.02479712,  0.00162404,  0.01082532],\n",
              "       [ 0.00055504,  0.00751592, -0.01533915,  0.00369111, -0.0212409 ,\n",
              "        -0.01776911, -0.00873537, -0.02636003],\n",
              "       [-0.1031505 , -0.09533153,  0.07332763,  0.09452222, -0.09128138,\n",
              "        -0.11597014,  0.14963062,  0.16030365],\n",
              "       [-0.02530686,  0.03538709,  0.00883675, -0.02922   ,  0.01038039,\n",
              "        -0.01332629,  0.04153463, -0.00159309],\n",
              "       [-0.0238721 , -0.02849039,  0.01068524, -0.03457545, -0.01397962,\n",
              "         0.00151281,  0.02734594,  0.01262411],\n",
              "       [ 0.01679302,  0.02677621, -0.00591351,  0.03327997,  0.04679294,\n",
              "         0.00922114, -0.0218071 , -0.02648896],\n",
              "       [-0.10389213, -0.11377577,  0.08453143,  0.10610738, -0.09379574,\n",
              "        -0.10738176,  0.13889943,  0.12366208],\n",
              "       [ 0.00369433,  0.04420095,  0.04950566, -0.01780283, -0.01317747,\n",
              "        -0.03314948, -0.03146247,  0.01765956],\n",
              "       [-0.02208217, -0.01711931, -0.03424181,  0.00659212, -0.016651  ,\n",
              "         0.04177723, -0.04469145,  0.01463706],\n",
              "       [-0.02015548,  0.01708615, -0.01653172, -0.04973036,  0.02384998,\n",
              "         0.01801267, -0.03710546,  0.00910002],\n",
              "       [ 0.02940029,  0.04469841,  0.04660937, -0.03940193, -0.03043996,\n",
              "         0.04283437,  0.011449  ,  0.04996334],\n",
              "       [ 0.0771016 , -0.1198892 ,  0.06722106,  0.15679552,  0.08196209,\n",
              "        -0.12078689, -0.11677691, -0.05380389],\n",
              "       [-0.04854259, -0.02185224, -0.00708265,  0.04979939,  0.02966893,\n",
              "        -0.04340143,  0.01671297,  0.03645242],\n",
              "       [ 0.04201389, -0.03618525, -0.02639116,  0.03312541,  0.03219805,\n",
              "        -0.03784493,  0.00017099,  0.02185274],\n",
              "       [ 0.08453526,  0.10508007, -0.07715602, -0.11337539, -0.00048857,\n",
              "         0.06562375, -0.03918001,  0.14255765],\n",
              "       [-0.13940616,  0.08280105, -0.14901128, -0.09862208, -0.05497701,\n",
              "         0.14578158,  0.11465027,  0.11512043]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# definicja funkcji standaryzującej\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "\n",
        "  return lowercase\n"
      ],
      "metadata": {
        "id": "0M4KdkbWbWAv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=Vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_length)\n",
        "\n"
      ],
      "metadata": {
        "id": "eUsE_KndZtqR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(reviews)"
      ],
      "metadata": {
        "id": "-yvo1prcbiwf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorize_layer.get_vocabulary()\n"
      ],
      "metadata": {
        "id": "CyMVoCj_b_9Y"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "id": "RmhB8uYncBZx",
        "outputId": "02cde0bc-0402-4aba-c1ba-6988819477b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'horrible',\n",
              " 'awesome',\n",
              " 'work',\n",
              " 'waitress',\n",
              " 'services!',\n",
              " 'service',\n",
              " 'rude',\n",
              " 'rocks',\n",
              " 'poor',\n",
              " 'never',\n",
              " 'have',\n",
              " 'food!',\n",
              " 'food',\n",
              " 'done',\n",
              " \"couldn't\",\n",
              " 'coming',\n",
              " 'cold',\n",
              " 'better',\n",
              " 'back!']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "out_v = io.open('/content/drive/MyDrive/dane/embeddings/vectors01.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('/content/drive/MyDrive/dane/embeddings/metadata01.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if index == 0:\n",
        "    continue  # pomijając 0, bo jest to wypełnienie.\n",
        "  vec = weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "k8a0FeNKcLQc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " http://projector.tensorflow.org/?_gl=1*rggcgk*_ga*NzAyNjA5OTg4LjE2OTQ1MDIxMDc.*_ga_W0YLR4190T*MTcwMDgyODU5Ny44LjEuMTcwMDgzMDA3MS4wLjAuMA..\n",
        ""
      ],
      "metadata": {
        "id": "0u7rcXMEdbec"
      }
    }
  ]
}