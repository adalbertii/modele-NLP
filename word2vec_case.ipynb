{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "gpuType": "T4",
      "mount_file_id": "https://github.com/adalbertii/modele-NLP/blob/main/word2vec_case.ipynb",
      "authorship_tag": "ABX9TyM6WS2BRr4Jka5CpI4nM481",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalbertii/modele-NLP/blob/main/word2vec_case.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Model wstepnie wytrenowany : gensim\n",
        "- https://radimrehurek.com/gensim/\n",
        "\n",
        "Wykorzystany w procesie uczenia modelu zbiór danych:  \n",
        "- http://kavita-ganesan.com/entity-ranking-data/"
      ],
      "metadata": {
        "id": "ZxGbU3-xPCyX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w2CgXseXyhF7"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zamontować dysk Google\n",
        "\n",
        "data_file=\"/content/drive/MyDrive/dane/word2vec/reviews_data.txt.gz\"\n",
        "\n",
        "with gzip.open (data_file, 'rb') as f:\n",
        "    for i,line in enumerate (f):\n",
        "        print(line)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1sBEZnCy1TN",
        "outputId": "4d6c0de3-9acf-4283-87d2-f40f05f3cf98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(line[:150])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp-qb7AkLD6o",
        "outputId": "02d11976-38ab-4d03-c989-2db68e1bdf69"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_input(input_file):\n",
        "    \"\"\"Metoda odczytuje plik wejściowy w formacie gzip\"\"\"\n",
        "\n",
        "    print(\"odczyt pliku {0}...to może zająć trochę czasu\".format(input_file))\n",
        "\n",
        "    with gzip.open (input_file, 'rb') as f:\n",
        "        for i, line in enumerate (f):\n",
        "\n",
        "            if (i%10000==0):\n",
        "                print (\"odczytano {0} opinii\".format (i))\n",
        "            # wykonaj wstępne przetwarzanie i zwróć listę słów dla każdego tekstu recenzji\n",
        "            yield gensim.utils.simple_preprocess (line)\n",
        "\n",
        "\n",
        "\n",
        "# Instrukcja Yield wstrzymuje wykonywanie funkcji i wysyła wartość z powrotem do funkcji wywołującej, ale zachowuje stan,\n",
        "# aby umożliwić wznowienie funkcji od miejsca, w którym została przerwana.\n",
        "# Po wznowieniu działania funkcja kontynuuje wykonywanie\n",
        "# Dzięki temu kod może generować w czasie serię wartości, zamiast wyznaczać je na raz i wysyłać z powrotem w formie listy."
      ],
      "metadata": {
        "id": "AQTrgxH_0ahJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# odczyt stokenizowanych opinii do listy\n",
        "# każdy element opinii  staje się serią słów\n",
        "#, więc budujemy listę list\n",
        "\n",
        "documents = list (read_input (data_file))\n",
        "print (\"Odczyt danych  z pliku zakńczony \")"
      ],
      "metadata": {
        "id": "md9ZwzBz0dc5",
        "outputId": "b35eda95-e359-4705-f846-27ef8cd8bcf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odczyt pliku /content/drive/MyDrive/dane/word2vec/reviews_data.txt.gz...to może zająć trochę czasu\n",
            "odczytano 0 opinii\n",
            "odczytano 10000 opinii\n",
            "odczytano 20000 opinii\n",
            "odczytano 30000 opinii\n",
            "odczytano 40000 opinii\n",
            "odczytano 50000 opinii\n",
            "odczytano 60000 opinii\n",
            "odczytano 70000 opinii\n",
            "odczytano 80000 opinii\n",
            "odczytano 90000 opinii\n",
            "odczytano 100000 opinii\n",
            "odczytano 110000 opinii\n",
            "odczytano 120000 opinii\n",
            "odczytano 130000 opinii\n",
            "odczytano 140000 opinii\n",
            "odczytano 150000 opinii\n",
            "odczytano 160000 opinii\n",
            "odczytano 170000 opinii\n",
            "odczytano 180000 opinii\n",
            "odczytano 190000 opinii\n",
            "odczytano 200000 opinii\n",
            "odczytano 210000 opinii\n",
            "odczytano 220000 opinii\n",
            "odczytano 230000 opinii\n",
            "odczytano 240000 opinii\n",
            "odczytano 250000 opinii\n",
            "Odczyt danych  z pliku zakńczony \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# budowa modelu\n",
        "# przy zainicjowanym T4 GPU procesorze zajmuje to około 30 minut\n",
        "\n",
        "model = gensim.models.Word2Vec(documents,\n",
        "                               window=10,   # Maksymalna odległość między bieżącym a przewidywanym słowem w zdaniu\n",
        "                               min_count=2, # Ignoruje wszystkie słowa o całkowitej częstotliwości mniejszej niż ta\n",
        "                               workers=10)  # ile wątków roboczych do szkolenia modelu\n",
        "                                            # (szybsze szkolenie na maszynach wielordzeniowych).\n",
        "\n",
        "model.train(documents,total_examples=len(documents),epochs=10)"
      ],
      "metadata": {
        "id": "qbZ92qqS0r1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/dane/modele/mymodel-wor2vec')"
      ],
      "metadata": {
        "id": "usOHd9Z37GdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Załadowanie wcześniej wytrenowanego modelu**"
      ],
      "metadata": {
        "id": "kwp2EZnekbSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = gensim.models.Word2Vec.load('/content/drive/MyDrive/dane/modele/mymodel-wor2vec')"
      ],
      "metadata": {
        "id": "u5JC6zjc7tzJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# jaka jest liczba wyrazów w modelu (korpusie modelu)\n",
        "new_model.corpus_total_words"
      ],
      "metadata": {
        "id": "793Q-gEFmF8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wyszukiwania słów podobnych do słowa 'dirty;\n",
        "# Spowoduje to zwrócenie 10 najpopularniejszych, podobnych słów.\n",
        "\n",
        "w1 = \"dirty\"\n",
        "new_model.wv.most_similar (positive=w1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJEHsByN7z2L",
        "outputId": "ecab012a-4564-422b-f47f-4458f541bab3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('filthy', 0.8984195590019226),\n",
              " ('grubby', 0.8221594095230103),\n",
              " ('smelly', 0.8083983063697815),\n",
              " ('unclean', 0.807628870010376),\n",
              " ('stained', 0.8064349293708801),\n",
              " ('dusty', 0.800523042678833),\n",
              " ('dingy', 0.7889810800552368),\n",
              " ('gross', 0.7759803533554077),\n",
              " ('mouldy', 0.7633497714996338),\n",
              " ('soiled', 0.7610918879508972)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wyszukanie 6 podobnych słów do słowa 'polite'\n",
        "\n",
        "w1 = [\"polite\"]\n",
        "new_model.wv.most_similar (positive=w1,topn=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOOwU3dD8B6m",
        "outputId": "e89a082a-b221-4c79-f829-d62a5abc7a00"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('courteous', 0.9318776726722717),\n",
              " ('friendly', 0.8612350225448608),\n",
              " ('cordial', 0.8443536758422852),\n",
              " ('curteous', 0.828039824962616),\n",
              " ('professional', 0.8158765435218811),\n",
              " ('attentive', 0.8073211312294006)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # wyszukanie 6 podobnych słów do słowa 'france'\n",
        "w1 = [\"france\"]\n",
        "new_model.wv.most_similar (positive=w1,topn=6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg_0czGb8Lqq",
        "outputId": "cbe3433f-5e5b-499c-c71b-0640bc5370e9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('germany', 0.7637171745300293),\n",
              " ('spain', 0.7122423052787781),\n",
              " ('hawaii', 0.7105596661567688),\n",
              " ('russia', 0.710435688495636),\n",
              " ('canada', 0.6956576108932495),\n",
              " ('austria', 0.6877645254135132)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wyszukanie 6 podobnych słów do słowa 'shocked'\n",
        "w1 = [\"shocked\"]\n",
        "new_model.wv.most_similar (positive=w1,topn=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPL-Wcw-8TCP",
        "outputId": "592dc27d-5f1b-4444-d6f5-0cde10abf08a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('horrified', 0.8368116617202759),\n",
              " ('amazed', 0.8187119960784912),\n",
              " ('dismayed', 0.7783960700035095),\n",
              " ('appalled', 0.7749536633491516),\n",
              " ('astounded', 0.7728244662284851),\n",
              " ('astonished', 0.7671551704406738)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wyznaczenie podobieństwa dwóch słów (wyrażonego liczbowo!!!)\n",
        "new_model.wv.similarity(w1=\"dirty\",w2=\"smelly\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kagjgvW8aFb",
        "outputId": "c6036987-ba0a-4b56-e9cd-bfc6d5f20ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8083983"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# podobieństwo poiędzy dwoma identycznymi wyrazami\n",
        "new_model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkXj5oI_8ubl",
        "outputId": "cdb670a4-3781-4940-d531-f6bd01a31010"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# similarity between two unrelated words\n",
        "new_model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7f_-AUB8zEt",
        "outputId": "5876cf12-172f-48fc-a13a-5567d80597e0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28794798"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testowanie gotowego modelu \"glove-twitter-25\"**\n",
        "\n",
        "Podstawowy zbiór danych: Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased)\n",
        "\n",
        "    https://nlp.stanford.edu/projects/glove/\n",
        "    https://nlp.stanford.edu/pubs/glove.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "uTitMlk8X6uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "88xmA5HHVhC_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove = api.load(\"glove-twitter-25\")"
      ],
      "metadata": {
        "id": "mTrNrumIVjQ0",
        "outputId": "444d94b4-16e5-461c-bfe8-95291fe4eea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove.most_similar(\"cat\", topn =10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-IDgGr5Vlan",
        "outputId": "6118921f-fea5-4b43-977b-e5e6c22adbea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dog', 0.9590820074081421),\n",
              " ('monkey', 0.920357882976532),\n",
              " ('bear', 0.9143136739730835),\n",
              " ('pet', 0.9108031392097473),\n",
              " ('girl', 0.8880629539489746),\n",
              " ('horse', 0.8872726559638977),\n",
              " ('kitty', 0.8870542049407959),\n",
              " ('puppy', 0.886769711971283),\n",
              " ('hot', 0.886525571346283),\n",
              " ('lady', 0.8845519423484802)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove.similarity('cat','dog')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RCYT_lMXQfh",
        "outputId": "89fcfe01-977d-499d-d464-06ff24f07ea1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.95908207"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model_glove.word_vec('cat')\n",
        "model_glove.get_vector('cat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA_KoBW_YHhz",
        "outputId": "cba62ac8-591e-471b-961c-ef1e3241c251"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.96419 , -0.60978 ,  0.67449 ,  0.35113 ,  0.41317 , -0.21241 ,\n",
              "        1.3796  ,  0.12854 ,  0.31567 ,  0.66325 ,  0.3391  , -0.18934 ,\n",
              "       -3.325   , -1.1491  , -0.4129  ,  0.2195  ,  0.8706  , -0.50616 ,\n",
              "       -0.12781 , -0.066965,  0.065761,  0.43927 ,  0.1758  , -0.56058 ,\n",
              "        0.13529 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_glove.get_vector('dog')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DojOxv3uYkoQ",
        "outputId": "0e0c9139-97fa-4288-f694-282bcc211af9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.2420e+00, -3.5980e-01,  5.7285e-01,  3.6675e-01,  6.0021e-01,\n",
              "       -1.8898e-01,  1.2729e+00, -3.6921e-01,  8.9080e-02,  4.0339e-01,\n",
              "        2.5130e-01, -2.5548e-01, -3.9209e+00, -1.1100e+00, -2.1308e-01,\n",
              "       -2.3846e-01,  9.5322e-01, -5.2750e-01, -7.8049e-04, -3.5771e-01,\n",
              "        5.5582e-01,  7.7869e-01,  4.6874e-01, -7.7803e-01,  7.8378e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#który wyraz nie pasuje?\n",
        "model_glove.doesnt_match([\"trump\",\"bernie\",\"obama\",\"pelosi\",\"orange\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dOANk1aUYr06",
        "outputId": "da249ee2-a58f-4d2f-e447-6c3f15cbd9ac"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'orange'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trenowanie modelu na bazie załadowanego korpusu**"
      ],
      "metadata": {
        "id": "HlRl2biSTNET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim.downloader as api\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "TATfRelWNzHO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# załądowanie korpusu  'text8'\n",
        "# Pierwsze 100 000 000 bajtów zwykłego tekstu z Wikipedii. Używane do celów testowych;\n",
        "\n",
        "# http://mattmahoney.net/dc/textdata.html\n",
        "# https://github.com/piskvorky/gensim-data/blob/master/README.md\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "corpus = api.load('text8')"
      ],
      "metadata": {
        "id": "GK2IYXDZnrAY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trenowanie modelu  Word2Vec\n",
        "# uczenie trwa prawie 3 minuty (przy aktywnym procesorze T4 GPU)\n",
        "\n",
        "model_text8 = Word2Vec(corpus,\n",
        "                       window=10,   # Maksymalna odległość między bieżącym a przewidywanym słowem w zdaniu\n",
        "                       min_count=2, # Ignoruje wszystkie słowa o całkowitej częstotliwości mniejszej niż 2\n",
        "                       workers=10)  # ile wątków roboczych do szkolenia modelu\n",
        "                                    #( szybsze szkolenie na maszynach wielordzeniowych).\n"
      ],
      "metadata": {
        "id": "wn0qxMDPN02J"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wyrazy podobne\n",
        "model_text8.wv.most_similar(\"shocked\")"
      ],
      "metadata": {
        "id": "klK2eeJuPcfn",
        "outputId": "42f6ca3f-8821-4abb-e5ef-f943bd00f543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('outraged', 0.8016893267631531),\n",
              " ('betrayed', 0.7413463592529297),\n",
              " ('upset', 0.6976285576820374),\n",
              " ('surprised', 0.6957406401634216),\n",
              " ('greeted', 0.6946792602539062),\n",
              " ('told', 0.6861076951026917),\n",
              " ('avenged', 0.6719164848327637),\n",
              " ('disappointed', 0.665448784828186),\n",
              " ('stabbed', 0.6623957753181458),\n",
              " ('beaten', 0.651833713054657)]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# podobieństwo pomiędzy dwoma wyrazami\n",
        "model_text8.wv.similarity(w1=\"dirty\",w2=\"smelly\")"
      ],
      "metadata": {
        "id": "0Y4LblM_Pe2t",
        "outputId": "4f603e98-a632-4442-e38f-dc5b665dff3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39632335"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Który z nich nie pasuje do pozostałych na liście ?\n",
        "model_text8.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
      ],
      "metadata": {
        "id": "eMWLOSlbPkVk",
        "outputId": "b760befc-bc33-484c-9b7e-a60bdbfb6241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'france'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    }
  ]
}